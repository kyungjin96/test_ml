{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_test02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmf+aQFfdseu8y3bB4xJ7O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyungjin96/test_ml/blob/main/ml_test02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooCZuy1PKOG1",
        "outputId": "18d4ac7f-6d39-4d4c-e16f-269b088d8b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2,)\n",
            "(2, 3)\n",
            "(3,)\n",
            "(3,)\n",
            "[0.30517326 1.3636486  1.91340808]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "X = np.random.rand(2)       # 입력\n",
        "W = np.random.rand(2, 3)    # 가중치\n",
        "B = np.random.rand(3)       # 편향\n",
        "\n",
        "print(X.shape)\n",
        "print(W.shape)\n",
        "print(B.shape)\n",
        "\n",
        "Y = np.dot(X, W) + B\n",
        "print(Y.shape)\n",
        "print(Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        \n",
        "        self.x = None\n",
        "        self.original_x_shape = None\n",
        "        # 가중치와 편향 매개변수의 미분\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 텐서 대응\n",
        "        self.original_x_shape = x.shape\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        self.x = x\n",
        "\n",
        "        out = np.dot(self.x, self.W) + self.b\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "        \n",
        "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
        "        return dx"
      ],
      "metadata": {
        "id": "xVGHS_tyKRyY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.loss = None # 손실함수\n",
        "        self.y = None    # softmax의 출력\n",
        "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
        "        \n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "        self.loss = cross_entropy_error(self.y, self.t)\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩 형태일 때\n",
        "            dx = (self.y - self.t) / batch_size\n",
        "        else:\n",
        "            dx = self.y.copy()\n",
        "            dx[np.arange(batch_size), self.t] -= 1\n",
        "            dx = dx / batch_size\n",
        "        \n",
        "        return dx\n"
      ],
      "metadata": {
        "id": "_Zmvl4JUKXBk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MNIST Dataset을 다운 받기 위한 셀로 볼 필요 없습니다.\n",
        "mnist_load()로 사용하면 됩니다.\n",
        "'''\n",
        "try:\n",
        "    import urllib.request\n",
        "except ImportError:\n",
        "    raise ImportError('You should use Python 3.x')\n",
        "import os.path\n",
        "import gzip\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
        "key_file = {\n",
        "    'train_img':'train-images-idx3-ubyte.gz',\n",
        "    'train_label':'train-labels-idx1-ubyte.gz',\n",
        "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
        "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "dataset_dir = os.path.dirname(os.path.abspath(''))\n",
        "save_file = dataset_dir + \"/mnist.pkl\"\n",
        "\n",
        "train_num = 60000\n",
        "test_num = 10000\n",
        "img_dim = (1, 28, 28)\n",
        "img_size = 784\n",
        "\n",
        "\n",
        "def _download(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    print(\"Downloading \" + file_name + \" ... \")\n",
        "    urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "    print(\"Done\")\n",
        "   \n",
        "def download_mnist():\n",
        "    for v in key_file.values():\n",
        "       _download(v)\n",
        "        \n",
        "def _load_label(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return labels\n",
        "\n",
        "def _load_img(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(-1, img_size)\n",
        "    print(\"Done\")    \n",
        "    return data\n",
        "    \n",
        "def _convert_numpy():\n",
        "    dataset = {}\n",
        "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
        "    dataset['train_label'] = _load_label(key_file['train_label'])    \n",
        "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
        "    dataset['test_label'] = _load_label(key_file['test_label'])    \n",
        "    return dataset\n",
        "\n",
        "def init_mnist():\n",
        "    download_mnist()\n",
        "    dataset = _convert_numpy()\n",
        "    print(\"Creating pickle file ...\")\n",
        "    with open(save_file, 'wb') as f:\n",
        "        pickle.dump(dataset, f, -1)\n",
        "    print(\"Done!\")\n",
        "\n",
        "def _change_one_hot_label(X):\n",
        "    T = np.zeros((X.size, 10))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1        \n",
        "    return T    \n",
        "\n",
        "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
        "    \"\"\"MNIST 데이터셋 읽기\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    normalize : 이미지의 픽셀 값을 0.0~1.0 사이의 값으로 정규화할지 정한다.\n",
        "    one_hot_label : \n",
        "        one_hot_label이 True면、레이블을 원-핫(one-hot) 배열로 돌려준다.\n",
        "        one-hot 배열은 예를 들어 [0,0,1,0,0,0,0,0,0,0]처럼 한 원소만 1인 배열이다.\n",
        "    flatten : 입력 이미지를 1차원 배열로 만들지를 정한다. \n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    (훈련 이미지, 훈련 레이블), (시험 이미지, 시험 레이블)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_file):\n",
        "        init_mnist()\n",
        "        \n",
        "    with open(save_file, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    \n",
        "    if normalize:\n",
        "        for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].astype(np.float32)\n",
        "            dataset[key] /= 255.0\n",
        "            \n",
        "    if one_hot_label:\n",
        "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
        "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])    \n",
        "    \n",
        "    if not flatten:\n",
        "         for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
        "\n",
        "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) "
      ],
      "metadata": {
        "id": "T96Fz0tWKZ-h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "신경망 구성을 위한 함수와 클래스 구현.\n",
        "'''\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T \n",
        "\n",
        "    x = x - np.max(x) # 오버플로 대책\n",
        "    return np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "        \n",
        "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "             \n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
        "\n",
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "        return dx\n",
        "\n",
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        \n",
        "        self.x = None\n",
        "        self.original_x_shape = None\n",
        "        # 가중치와 편향 매개변수의 미분\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 텐서 대응\n",
        "        self.original_x_shape = x.shape\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        self.x = x\n",
        "\n",
        "        out = np.dot(self.x, self.W) + self.b\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
        "        return dx\n",
        "\n",
        "\n",
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.loss = None # 손실함수\n",
        "        self.y = None    # softmax의 출력\n",
        "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
        "        \n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "        self.loss = cross_entropy_error(self.y, self.t)\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩 형태일 때\n",
        "            dx = (self.y - self.t) / batch_size\n",
        "        else:\n",
        "            dx = self.y.copy()\n",
        "            dx[np.arange(batch_size), self.t] -= 1\n",
        "            dx = dx / batch_size\n",
        "      \n",
        "        return dx"
      ],
      "metadata": {
        "id": "SixdnMnQKbNx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "'''\n",
        "4장에서 구현한 2층 신경망을 오차역전파법을 사용하여 학습을 구현함.\n",
        "'''\n",
        "class TwoLayerNet:\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
        "        # 가중치 초기화\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "        # 계층 생성\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
        "        self.layers['Relu1'] = Relu()\n",
        "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
        "\n",
        "        self.lastLayer = SoftmaxWithLoss()\n",
        "        # Affine1 -> Relu1 -> Affine2 -> Softmax 의 레이어를 갖는 신경망을 구현.\n",
        "        \n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)        \n",
        "        return x\n",
        "        \n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        return self.lastLayer.forward(y, t)\n",
        "    \n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "        \n",
        "    # x : 입력 데이터, t : 정답 레이블     \n",
        "    def gradient(self, x, t):\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1                                # 역전파의 초기 신호를 1으로 설정,\n",
        "        dout = self.lastLayer.backward(dout)    # 역전파를 계산하여 해당 레이어 클래스에 기울기(Gradient)를 저장.\n",
        "        \n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 결과 저장\n",
        "        grads = {}\n",
        "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
        "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
        "\n",
        "        return grads\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "    \n",
        "    # 기울기 계산\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "    \n",
        "    # 갱신\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]    # 학습 후 계산한 기울기(Gradient)로 경사하강법을 사용하여 학습.\n",
        "    \n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "    \n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(\"epoch :\", int(i / iter_per_epoch))\n",
        "        print(\"train_acc : %.4f\" % (train_acc))\n",
        "        print(\"test_acc : %.4f\" % (test_acc))\n",
        "        print()\n",
        "\n",
        "# draw acc graph.\n",
        "x = np.arange(1, len(train_acc_list) + 1)\n",
        "plt.plot(x, train_acc_list, label='train Acc')\n",
        "plt.plot(x, test_acc_list, label='test Acc', linestyle='--')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s7CMb_TqKctq",
        "outputId": "022805d1-79f8-41bf-d492-a489c59a4206"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train-images-idx3-ubyte.gz ... \n",
            "Done\n",
            "Downloading train-labels-idx1-ubyte.gz ... \n",
            "Done\n",
            "Downloading t10k-images-idx3-ubyte.gz ... \n",
            "Done\n",
            "Downloading t10k-labels-idx1-ubyte.gz ... \n",
            "Done\n",
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Creating pickle file ...\n",
            "Done!\n",
            "epoch : 0\n",
            "train_acc : 0.1560\n",
            "test_acc : 0.1579\n",
            "\n",
            "epoch : 1\n",
            "train_acc : 0.9020\n",
            "test_acc : 0.9029\n",
            "\n",
            "epoch : 2\n",
            "train_acc : 0.9218\n",
            "test_acc : 0.9260\n",
            "\n",
            "epoch : 3\n",
            "train_acc : 0.9348\n",
            "test_acc : 0.9341\n",
            "\n",
            "epoch : 4\n",
            "train_acc : 0.9432\n",
            "test_acc : 0.9406\n",
            "\n",
            "epoch : 5\n",
            "train_acc : 0.9504\n",
            "test_acc : 0.9470\n",
            "\n",
            "epoch : 6\n",
            "train_acc : 0.9542\n",
            "test_acc : 0.9508\n",
            "\n",
            "epoch : 7\n",
            "train_acc : 0.9600\n",
            "test_acc : 0.9569\n",
            "\n",
            "epoch : 8\n",
            "train_acc : 0.9631\n",
            "test_acc : 0.9585\n",
            "\n",
            "epoch : 9\n",
            "train_acc : 0.9672\n",
            "test_acc : 0.9623\n",
            "\n",
            "epoch : 10\n",
            "train_acc : 0.9700\n",
            "test_acc : 0.9623\n",
            "\n",
            "epoch : 11\n",
            "train_acc : 0.9720\n",
            "test_acc : 0.9666\n",
            "\n",
            "epoch : 12\n",
            "train_acc : 0.9733\n",
            "test_acc : 0.9674\n",
            "\n",
            "epoch : 13\n",
            "train_acc : 0.9754\n",
            "test_acc : 0.9672\n",
            "\n",
            "epoch : 14\n",
            "train_acc : 0.9774\n",
            "test_acc : 0.9700\n",
            "\n",
            "epoch : 15\n",
            "train_acc : 0.9787\n",
            "test_acc : 0.9688\n",
            "\n",
            "epoch : 16\n",
            "train_acc : 0.9791\n",
            "test_acc : 0.9695\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YanbVZFsKfUh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}